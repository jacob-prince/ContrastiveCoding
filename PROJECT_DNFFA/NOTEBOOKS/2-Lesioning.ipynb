{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb5595-a9de-40e5-870a-61f7038b3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff55b1b-6d11-4984-8efb-a4ec477371e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsputils import classes, nnutils, feature_extractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import gc\n",
    "import os\n",
    "from os.path import exists\n",
    "import json\n",
    "import copy\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import seaborn as sns\n",
    "from fastprogress import progress_bar\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d84546-832b-49bb-8726-84c5aa84e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'alexnet-barlow-twins'\n",
    "floc_imageset_name = 'vpnl-floc'\n",
    "\n",
    "figure_savedir = f'{os.getcwd()}/figure_outputs/Figure2-Lesioning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096d0ee-bb06-4913-9642-04b8483f5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN = classes.DNNModel(model_name)\n",
    "\n",
    "DNN.append_readout_layer(readout_from = 'relu7')\n",
    "DNN.load_readout_weights(description = 'mdl-alexnet-barlow-twins_from-relu7_mlr-0.05_ilr-0.001_eps-10_sparse-pos-True_l1p-1e-05_l1n-1e-05',\n",
    "    device = 'cpu')\n",
    "#DNN.load_readout_weights(description = 'mdl-alexnet-barlow-twins_from-relu7_mlr-0.05_ilr-0.001_eps-10_sparse-pos-False',\n",
    "#                        device = 'cpu')\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9b9f2-4da8-4bbe-806e-67840adaec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = DNN.readout_model.readout.weight.detach().numpy()\n",
    "\n",
    "plt.imshow(weights,aspect='auto',cmap='RdBu_r',clim=(-0.01,0.01))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe720267-a94b-4fbd-b3b0-28f776088954",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.001\n",
    "np.mean(np.abs(weights) < eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004eb5aa-4f24-411c-836f-a424394f1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.abs(weights)))\n",
    "print(np.std(np.abs(weights)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15865d93-fe08-45fd-a83f-4dbf46990b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN.find_selective_units(floc_imageset_name, overwrite = False, verbose = False,\n",
    "                        FDR_p = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d1601-011e-4e76-80c6-3eebd0a186db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN.model = DNN.readout_model\n",
    "DNN.layer_names_fmt, _ = feature_extractor.get_pretty_layer_names(DNN.readout_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90a4f4-2b9e-4026-bce9-20bfbd592e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSN = classes.LesionModel(DNN, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76601a-7c78-49c3-a207-4a076eafc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSN.model.return_acts = False\n",
    "LSN.model.masks['apply'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6077dd-fd64-4a03-8cae-2072b01cf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSN.get_imagenet_accs(topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11bb2a-f971-4094-bb23-a917849b5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelesion_accs = LSN.imagenet_accs\n",
    "print(np.mean(prelesion_accs))\n",
    "print(np.std(prelesion_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02e005-d312-4921-af74-cad695a725fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LSN.get_selective_unit_acts(layers = DNN.layer_names_fmt[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ba11d-b3b8-4dd0-bac2-1d04493b34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383c35f-0a81-4837-a0fd-cc08533c372d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "results = dict()\n",
    "results['acc'] = prelesion_accs\n",
    "\n",
    "for domain in progress_bar(['faces','scenes','bodies','characters',\n",
    "                            'objects','scrambled']):\n",
    "\n",
    "    results[domain] = dict()\n",
    "    \n",
    "    LSN.model.return_acts = False\n",
    "\n",
    "    LSN.apply_channelized_lesions(domain, \n",
    "                                  method = 'relus')\n",
    "\n",
    "    LSN.model.masks['apply'] = True\n",
    "    \n",
    "    LSN.get_imagenet_accs(topk=5)\n",
    "\n",
    "    results[domain]['lsn_acc'] = LSN.imagenet_accs\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94509a-c5eb-453c-8efc-ed5a3e25b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a044d9-bdc8-42bf-9821-81ef26cd0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_corr(x,y,linecols = ['r'], bigks = [None], e1 = None, e2 = 0.5):\n",
    "    np.random.seed(0)\n",
    "    if e1 is None:\n",
    "        ep1 = np.zeros((len(x),))\n",
    "    else:\n",
    "        ep1 = np.random.normal(0,e1,len(x))\n",
    "    ep2 = np.random.normal(0,e2,len(y))\n",
    "    sizes = np.array([150] * len(y))\n",
    "    colors = ['darkgray'] * len(y)\n",
    "    if bigks[0]: \n",
    "        for bk, bigk in enumerate(bigks):\n",
    "            if bk == 0 and len(bigks) == 1:\n",
    "                idx = np.argsort(y)\n",
    "            elif bk == 0 and len(bigks) == 2:\n",
    "                idx = np.argsort(x)\n",
    "            elif bk == 1:\n",
    "                idx = np.argsort(y)\n",
    "            \n",
    "            sizes[idx[:bigk]] = 400\n",
    "            for k in range(bigk):\n",
    "                colors[idx[:bigk][k]] = linecols[bk]\n",
    "    colors = np.array(colors)\n",
    "            \n",
    "    if len(linecols) == 2:\n",
    "        linecol_ = 'k'\n",
    "    else:\n",
    "        linecol_ = linecols[0]\n",
    "        \n",
    "    plt.scatter(x+ep1,y+ep2,sizes,c=colors)\n",
    "    plt.plot(np.unique(x+ep1), np.poly1d(np.polyfit(x+ep1, y+ep2, 1))(np.unique(x+ep1)),color=linecol_,linewidth=20)\n",
    "    # if len(choose_layer) > 0:\n",
    "    #     plt.title(f'read-out effect: \\nlayer {max_layer}: r = {round(np.corrcoef(x,y)[1,0],3)}',\n",
    "    #          fontsize=20)\n",
    "    # else:\n",
    "    print(f'r = {round(np.corrcoef(x,y)[1,0],3)}')\n",
    "    #plt.title(f'r = {round(np.corrcoef(x,y)[1,0],3)}',\n",
    "    #          fontsize=20)\n",
    "    #plt.xlabel('mean categ. activation',fontsize=14)\n",
    "    #plt.ylabel('drop in acc',fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230404bd-74ec-4645-9062-3a0c103324f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer = 'relu6'\n",
    "rs = []\n",
    "colors = ['red','dodgerblue','limegreen','purple']\n",
    "#colors = ['tomato', [0.196, 0.804, 0.196], 'dodgerblue', 'purple']\n",
    "\n",
    "for d, domain in enumerate(['faces','bodies','scenes','characters']):#,'objects','scrambled']:\n",
    "    \n",
    "    x = copy.deepcopy(LSN.selective_unit_acts[domain][plot_layer])\n",
    "    y = -100 * copy.deepcopy((results['acc'] - results[domain]['lsn_acc']))# / results['acc']\n",
    "    \n",
    "    notnan = np.logical_and(np.logical_not(np.isnan(x)),\n",
    "                           np.logical_not(np.isnan(y)))\n",
    "    notinf = np.logical_and(np.logical_not(np.isinf(x)),\n",
    "                           np.logical_not(np.isinf(y)))\n",
    "    \n",
    "    valid = np.logical_and(notnan, notinf)\n",
    "    \n",
    "    if np.sum(valid) > 750:\n",
    "        r = stats.pearsonr(x[valid],y[valid])[0]\n",
    "        \n",
    "        \n",
    "        rs.append(r)\n",
    "        plt.figure(figsize=(24,24))\n",
    "        scatter_corr(x[valid],y[valid],linecols = [colors[d]],bigks=[10])\n",
    "        plt.xticks(fontsize=75)\n",
    "        plt.yticks(fontsize=75)\n",
    "        #plt.xlim([0,1])\n",
    "        plt.savefig(f\"{figure_savedir}/scatter_corr_{domain}.tiff\")\n",
    "        plt.close()\n",
    "       \n",
    "    else:\n",
    "        print('skipping',domain,layer,np.sum(valid))\n",
    "        \n",
    "print(np.mean(rs), np.std(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0775b-e03d-4fe4-8653-753a9abfe111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers = DNN.layer_names_fmt[:-1]\n",
    "plt.figure(figsize=(16,9))\n",
    "ft = 24\n",
    "\n",
    "color_dict = {'faces':'tomato',\n",
    "          'bodies':'dodgerblue',\n",
    "          'objects':'orange',\n",
    "          'scenes':'limegreen',\n",
    "          'characters':'purple',\n",
    "          'scrambled':'navy'}\n",
    "\n",
    "layer_list = []\n",
    "\n",
    "for layer in plot_layers:\n",
    "    if not 'flatten' in layer:\n",
    "        layer_list.append(layer)\n",
    "\n",
    "for domain in ['faces','scenes','bodies','characters','objects']:\n",
    "    \n",
    "    rs = []\n",
    "    y = -100 * (results['acc'] - results[domain]['lsn_acc'])# / results['acc']\n",
    "    \n",
    "    for plot_layer in layer_list:\n",
    "    \n",
    "        x = LSN.selective_unit_acts[domain][plot_layer]\n",
    "        \n",
    "    \n",
    "        notnan = np.logical_and(np.logical_not(np.isnan(x)),\n",
    "                               np.logical_not(np.isnan(y)))\n",
    "        notinf = np.logical_and(np.logical_not(np.isinf(x)),\n",
    "                               np.logical_not(np.isinf(y)))\n",
    "\n",
    "        valid = np.logical_and(notnan, notinf)\n",
    "    \n",
    "        if np.sum(valid) > 750:\n",
    "            r = stats.pearsonr(x[valid],y[valid])[0]\n",
    "            rs.append(r)\n",
    "        else:\n",
    "            #print(domain, layer, np.sum(valid))\n",
    "            rs.append(np.nan)\n",
    "            \n",
    "    if domain == 'characters':\n",
    "        label = 'words'\n",
    "    else:\n",
    "        label = domain\n",
    "            \n",
    "    plt.plot(rs,label=label,color=color_dict[domain],linewidth=5);\n",
    "        \n",
    "#plt.title(f'Correlation between activation and cost profiles',fontsize=ft)\n",
    "#plt.ylabel('Pearson r',fontsize=ft)\n",
    "plt.xticks(np.arange(len(layer_list)),np.array(layer_list),rotation=90,fontsize=ft);\n",
    "    #plt.title(f'proportion of domain-selective units by layer (FDR_p = {FDR_p})\\nmodel: {model_name}\\nfloc set: {floc_imageset}')\n",
    "plt.grid('on')\n",
    "# get rid of the frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "plt.ylim([-1,0.2])\n",
    "plt.plot(np.arange(len(layer_list)), np.zeros((len(layer_list),)), color='k',linewidth=3)\n",
    "plt.yticks(fontsize=ft)\n",
    "plt.legend(fontsize=ft-3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_savedir}/readout_effect_summary.tiff\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89562f0-dc0b-4864-848a-e117d024dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "cost_corrs = []\n",
    "\n",
    "for domain in ['faces','bodies','scenes','characters','objects']:\n",
    "    \n",
    "    costs.append(results['acc'] - results[domain]['lsn_acc'])\n",
    "    \n",
    "costs = np.vstack(costs)\n",
    "\n",
    "cost_corrs = pdist(costs,'correlation')\n",
    "\n",
    "print(np.mean(1 - cost_corrs))\n",
    "print(np.std(1 - cost_corrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a849c4-ae73-4a22-89e9-bfe65d3308c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5*4,4*4))\n",
    "sns.heatmap(1 - squareform(cost_corrs), annot = True, cmap = 'RdBu_r', vmin = -1, vmax = 1, annot_kws={\"size\": 40})\n",
    "plt.xticks([])\n",
    "plt.yticks([]);\n",
    "plt.savefig(f\"{figure_savedir}/cost_corr_domain_summary.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72858706-80a0-4eaa-8cf2-73ff62521b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['faces','bodies','scenes','characters','objects']\n",
    "\n",
    "dom_pairs = [[0,2],\n",
    "             [0,3]]\n",
    "\n",
    "for dom_pair in dom_pairs:\n",
    "    dA, dB = dom_pair\n",
    "\n",
    "    plt.figure(figsize=(24,24))\n",
    "\n",
    "    scatter_corr(-100*copy.deepcopy(costs[dA]),\n",
    "                 -100*copy.deepcopy(costs[dB]), e1 = 0.5, e2 = 0.5, bigks=[10,10],\n",
    "                                     linecols=[colors[dA],\n",
    "                                               colors[dB]])\n",
    "    plt.xticks(fontsize=75)\n",
    "    plt.yticks(fontsize=75)\n",
    "    #plt.xlim([-0.33,0.84])\n",
    "    #plt.ylim([-0.33,0.84])\n",
    "    #plt.axis('square');\n",
    "    \n",
    "    plt.savefig(f\"{figure_savedir}/dissociation_{domains[dom_pair[0]]}-{domains[dom_pair[1]]}.tiff\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217ea6d-15c5-44d2-88c1-25541d6ebd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_cv = dict()\n",
    "\n",
    "# unlesioned case\n",
    "LSN.model.masks['apply'] = False\n",
    "LSN.model.return_acts = False\n",
    "LSN.get_imagenet_accs(topk = 5, cv = True)\n",
    "\n",
    "results_cv['acc_splitA'] =  LSN.imagenet_accs[:,0]\n",
    "results_cv['acc_splitB'] =  LSN.imagenet_accs[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8451a0-39bd-4cdd-b0a8-a6bd97cb613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_cv['acc_splitB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0eeed-99de-4cbc-aeb4-db336e6c6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file containing the ImageNet class index\n",
    "with open(f'{os.getcwd()}/imagenet_class_labels.json', 'r') as f:\n",
    "    class_index = json.load(f)\n",
    "\n",
    "# Create a list to store the category labels\n",
    "categories = []\n",
    "\n",
    "# Iterate over the class index dictionary and extract the labels\n",
    "for idx in range(len(class_index)):\n",
    "    categories.append(class_index[idx])\n",
    "categories = np.array(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696415fb-2e6e-466f-899f-3c6b64191479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for domain in progress_bar(['faces','scenes','bodies','characters']):\n",
    "\n",
    "    results_cv[domain] = dict()\n",
    "    \n",
    "    LSN.model.return_acts = False\n",
    "\n",
    "    LSN.apply_channelized_lesions(domain, \n",
    "                                  method = 'relus')\n",
    "\n",
    "    LSN.model.masks['apply'] = True\n",
    "\n",
    "    LSN.get_imagenet_accs(topk = 5, cv = True)\n",
    "\n",
    "    results_cv[domain]['lsn_acc_splitA'] = LSN.imagenet_accs[:,0]\n",
    "    results_cv[domain]['lsn_acc_splitB'] = LSN.imagenet_accs[:,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00545037-38d6-4c5a-aba7-bfb5926b7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['faces','bodies','scenes','characters']\n",
    "c=1\n",
    "ks = [5,10,25,50,75,100]\n",
    "plt.figure(figsize=(12,len(ks)*5))\n",
    "\n",
    "prop = False\n",
    "\n",
    "for k in ks:\n",
    "\n",
    "    domain_costs = dict()\n",
    "    top_k_indices = dict()\n",
    "    mean_drop = dict()\n",
    "    sem_drop = dict()\n",
    "\n",
    "    for lsn_domain in domains:\n",
    "\n",
    "        mean_drop[lsn_domain] = dict()\n",
    "        sem_drop[lsn_domain] = dict()\n",
    "        \n",
    "        for sp in ['A','B']:\n",
    "\n",
    "            if prop:\n",
    "                domain_costs[f'{lsn_domain}_split{sp}'] = (results_cv[f'acc_split{sp}'] - results_cv[lsn_domain][f'lsn_acc_split{sp}']) / results_cv[f'acc_split{sp}']\n",
    "            else:\n",
    "                domain_costs[f'{lsn_domain}_split{sp}'] = (results_cv[f'acc_split{sp}'] - results_cv[lsn_domain][f'lsn_acc_split{sp}'])\n",
    "\n",
    "            domain_costs[f'{lsn_domain}_split{sp}'][np.isinf(domain_costs[f'{lsn_domain}_split{sp}'])] = 0\n",
    "            domain_costs[f'{lsn_domain}_split{sp}'][np.isnan(domain_costs[f'{lsn_domain}_split{sp}'])] = 0\n",
    "        \n",
    "        cost_sort_idx = np.argsort(domain_costs[f'{lsn_domain}_splitA'])\n",
    "        assert(np.sum(np.isnan(domain_costs[f'{lsn_domain}_splitA'])) == 0)\n",
    "\n",
    "        top_k_indices[lsn_domain] = cost_sort_idx[-k:]\n",
    "\n",
    "    for lsn_domain in domains:\n",
    "        for probe_domain in domains:\n",
    "            mean_drop[lsn_domain][probe_domain] = np.mean(domain_costs[f'{lsn_domain}_splitB'][top_k_indices[probe_domain]])\n",
    "            sem_drop[lsn_domain][probe_domain] = np.std(domain_costs[f'{lsn_domain}_splitB'][top_k_indices[probe_domain]]) / np.sqrt(k)\n",
    "\n",
    "            #print(lsn_domain, probe_domain, mean_drop[lsn_domain][probe_domain])\n",
    "\n",
    "        if k == 10:\n",
    "            vals = domain_costs[f'{lsn_domain}_splitB'][top_k_indices[lsn_domain]]\n",
    "            print(lsn_domain, np.mean(vals), np.std(vals))\n",
    "            \n",
    "    # Create the x position of the bars\n",
    "    x = np.arange(len(domains))\n",
    "\n",
    "    # Create the bars\n",
    "    bar_width = 0.18\n",
    "    gap = 0.1\n",
    "    colors = ['tomato', 'dodgerblue', 'limegreen', 'purple']#'navy']#, 'orange']\n",
    "\n",
    "    plt.subplot(len(ks),1,c)\n",
    "    for i, probe_domain in enumerate(domains):\n",
    "        means = -100 * copy.deepcopy(np.array([mean_drop[lsn_domain][probe_domain] for lsn_domain in domains]))\n",
    "        plt.bar(x + i*bar_width, means, width = bar_width, color = colors[i],\n",
    "                yerr =  100*np.array([sem_drop[lsn_domain][probe_domain] for lsn_domain in domains]))\n",
    "\n",
    "\n",
    "    # Add some text for labels, title\n",
    "    #plt.title(f'Lesioning impact on most domain-relevant categories, k = {k}')\n",
    "    #plt.xticks(x + bar_width*1.5, [f'{domain}\\nlesions' for domain in domains])\n",
    "    plt.hlines(0,0,3.5,'k',linewidth=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.box('off')\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "    plt.yticks(fontsize=25)\n",
    " \n",
    "    plt.grid('on')\n",
    "    \n",
    "    if prop:\n",
    "        #plt.ylabel('Mean change in accuracy (proportion)')\n",
    "        plt.ylim([-110, 25])\n",
    "    else:\n",
    "        #plt.ylabel('Mean change in accuracy (absolute %)')\n",
    "        plt.ylim([-70, 15])\n",
    "    c+=1\n",
    "\n",
    "# show the graph\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_savedir}/dissociation_bars_k_summary.tiff\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310a621-2e6d-48ff-b494-6ca2821e8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "\n",
    "indices = dict()\n",
    "\n",
    "domains = ['faces','bodies','scenes','characters']\n",
    "# use half the data to get the special categs for each domain\n",
    "for domain in domains:\n",
    "    costs = results_cv['acc_splitA'] - results_cv[domain]['lsn_acc_splitA']\n",
    "    indices[domain] = np.flip(np.argsort(costs)[-k:])\n",
    "    print(domain, categories[indices[domain]], '\\naccuracy drops:', costs[indices[domain]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69183dc-3afb-4ce5-96f1-5eda056f6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoader = classes.DataLoaderFFCV('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc7c89-b877-4bc0-a889-45825ddf045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = torch.Tensor(50000, 3, 224, 224)\n",
    "val_targets = torch.Tensor(50000)\n",
    "batch_size = ValLoader.batch_size\n",
    "\n",
    "c = 0\n",
    "for images, targets, _, _ in progress_bar(ValLoader.data_loader):\n",
    "    val_images[c:c+batch_size] = images\n",
    "    val_targets[c:c+batch_size] = targets\n",
    "    c+=batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ea812-6160-4e59-a865-b903afc7f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_images = torch.Tensor(5000, 3, 224, 224)\n",
    "probe_targets = torch.arange(1000)\n",
    "\n",
    "c = 0\n",
    "for i in range(1000):\n",
    "    idx = np.squeeze(np.argwhere(val_targets == i))\n",
    "    for j in range(5):\n",
    "        probe_images[c+j] = val_images[idx[0+j]]\n",
    "    c+=5\n",
    "    \n",
    "del val_images, val_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eae0fc-ce4a-4f21-a3cb-2eae96824a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e7b67-66c4-4b8e-92c4-6c0670c8e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file containing the ImageNet class index\n",
    "with open(f'{os.getcwd()}/imagenet_class_labels.json', 'r') as f:\n",
    "    class_index = json.load(f)\n",
    "\n",
    "# Create a list to store the category labels\n",
    "categories = []\n",
    "\n",
    "# Iterate over the class index dictionary and extract the labels\n",
    "for idx in range(len(class_index)):\n",
    "    categories.append(class_index[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a808003-c401-4637-b411-ee05c0b54e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean and standard deviation values used for normalization\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4eb393-f968-4db8-9aa1-2317b92882f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain in ['faces','scenes','bodies','characters']:#'faces','scenes','bodies','characters']:\n",
    "\n",
    "    costs = results_cv['acc_splitA'] - results_cv[domain]['lsn_acc_splitA']\n",
    "    #costs = results['acc'] - results[domain]['lsn_acc']\n",
    "    acts = LSN.selective_unit_acts[domain][plot_layer]\n",
    "\n",
    "    rankings = np.flip(np.argsort(costs))\n",
    "\n",
    "    for i in range(8):\n",
    "        \n",
    "        for j in range(6):\n",
    "            \n",
    "            plt.figure(figsize=(20,20))\n",
    "\n",
    "            categ_idx = rankings[i]\n",
    "\n",
    "            loss = costs[rankings[i]]#100 * costs[rankings[i]] / results['acc'][rankings[i]]\n",
    "\n",
    "            img = probe_images[categ_idx*5+j].numpy().transpose(1,2,0)\n",
    "\n",
    "            # Undo the normalization\n",
    "            restored_image = img * std + mean\n",
    "\n",
    "            # Clip the values to ensure they are within the valid range [0, 1]\n",
    "            restored_image = np.clip(restored_image, 0, 1)\n",
    "\n",
    "            plt.imshow(restored_image)\n",
    "            plt.axis('off')\n",
    "            #plt.title(f'{categories[categ_idx]} ({round(loss,2)})')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{figure_savedir}/{domain}-impaired-{i}-{categories[categ_idx]}-{round(loss,2)}-{j}.tiff\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a16e-6b92-4f44-9cc8-db91a69f9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized lesions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0b87f-a928-43e2-9a90-68cb47fd417b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "savefn = f'{os.getcwd()}/analysis_outputs/2-Lesioning/randomized_lesion_results.npy'\n",
    "n_iters = 10\n",
    "\n",
    "plot_layers = DNN.layer_names_fmt[:-1]\n",
    "\n",
    "colors = {'faces':'tomato',\n",
    "          'bodies':'dodgerblue',\n",
    "          'objects':'orange',\n",
    "          'scenes':'limegreen',\n",
    "          'characters':'purple',\n",
    "          'scrambled':'navy'}\n",
    "\n",
    "if exists(savefn) and not overwrite:\n",
    "    \n",
    "    results_rand = np.load(savefn,allow_pickle=True).item()\n",
    "    \n",
    "else:\n",
    "    \n",
    "    results_rand = dict()\n",
    "    results_rand['acc'] = prelesion_accs\n",
    "    for domain in ['faces','scenes','bodies','characters',\n",
    "                                    'objects']:\n",
    "        results_rand[domain] = dict()\n",
    "        results_rand[domain]['lsn_acc'] = []\n",
    "        results_rand[domain]['rs'] = []\n",
    "\n",
    "    for i in progress_bar(range(n_iters)):\n",
    "\n",
    "        LSN.randomize_selective_unit_indices()\n",
    "        LSN.get_selective_unit_acts(layers = DNN.layer_names_fmt[:-1])\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        LSN.model.return_acts = False\n",
    "\n",
    "        for domain in progress_bar(['faces','scenes','bodies','characters',\n",
    "                                    'objects']):\n",
    "\n",
    "            LSN.apply_channelized_lesions(domain, \n",
    "                                          method = 'relus')\n",
    "\n",
    "            LSN.model.masks['apply'] = True\n",
    "\n",
    "            LSN.get_imagenet_accs(topk=5)\n",
    "\n",
    "            postlesion_accs = LSN.imagenet_accs\n",
    "\n",
    "            results_rand[domain]['lsn_acc'].append(postlesion_accs)\n",
    "\n",
    "            rs = []\n",
    "            y = (results_rand['acc'] - postlesion_accs)\n",
    "\n",
    "            for plot_layer in layer_list:\n",
    "\n",
    "                x = LSN.selective_unit_acts[domain][plot_layer]\n",
    "\n",
    "                notnan = np.logical_and(np.logical_not(np.isnan(x)),\n",
    "                                       np.logical_not(np.isnan(y)))\n",
    "                notinf = np.logical_and(np.logical_not(np.isinf(x)),\n",
    "                                       np.logical_not(np.isinf(y)))\n",
    "\n",
    "                valid = np.logical_and(notnan, notinf)\n",
    "\n",
    "                if np.sum(valid) > 750:\n",
    "                    r = stats.pearsonr(x[valid],y[valid])[0]\n",
    "                    rs.append(r)\n",
    "                else:\n",
    "                    #print(domain, layer, np.sum(valid))\n",
    "                    rs.append(np.nan)\n",
    "\n",
    "            results_rand[domain]['rs'].append(rs)\n",
    "            \n",
    "    np.save(savefn, results_rand, allow_pickle=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958c46b-c402-484b-80bb-5396c80b2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "ft = 24\n",
    "\n",
    "for domain in ['faces','scenes','bodies','characters','objects']:\n",
    "    rs = -1 * np.stack(results_rand[domain]['rs'],axis=1)\n",
    "    rs_mean = np.mean(rs,axis=1)\n",
    "    rs_sem = np.std(rs,axis=1) / np.sqrt(n_iters)\n",
    "    \n",
    "    if domain == 'characters':\n",
    "        label = 'words'\n",
    "    else:\n",
    "        label = domain\n",
    "            \n",
    "    plt.plot(rs_mean,label=label,color=colors[domain],linewidth=3);\n",
    "    plt.fill_between(np.arange(len(layer_list)), rs_mean - rs_sem, rs_mean + rs_sem, color=colors[domain],\n",
    "                     alpha=0.3)\n",
    "        \n",
    "#plt.title(f'Correlation between activation and cost profiles',fontsize=ft)\n",
    "#plt.ylabel('Pearson r',fontsize=ft)\n",
    "plt.xticks(np.arange(len(layer_list)),np.array(layer_list),rotation=90,fontsize=ft);\n",
    "    #plt.title(f'proportion of domain-selective units by layer (FDR_p = {FDR_p})\\nmodel: {model_name}\\nfloc set: {floc_imageset}')\n",
    "plt.grid('on')\n",
    "# get rid of the frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "plt.ylim([-1,0.2])\n",
    "plt.plot(np.arange(len(layer_list)), np.zeros((len(layer_list),)), color='k',linewidth=3)\n",
    "plt.yticks(fontsize=ft)\n",
    "plt.legend(fontsize=ft-3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{figure_savedir}/readout_effect_summary_randomized.tiff\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e29fa-72e6-4fb9-bd6b-40dd25b73bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnffa",
   "language": "python",
   "name": "dnffa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
